description: This command runs an evaluation for the specified platform and saves results to specified location.
parameters:
  cmd:
    description: command to execute
    type: string
  circle_pipeline_id:
    description: CircleCI Pipeline ID
    type: string
  braintrust_experiment_name:
    description: Braintrust experiment name
    type: string
    default: ""
  langsmith_experiment_name:
    description: Langsmith experiment name
    type: string
    default: ""
  langsmith_endpoint:
    description: Langsmith endpoint
    type: string
    default: ""
  evals_result_location:
    description: evaluation result location
    type: string
    default: "./results"
  eval_platform:
    description: evaluation platform
    type: string
    default: "custom"
    enum:
      - braintrust
      - langsmith
      - custom
  shell:
    description: shell to use
    type: string
    default: /bin/bash
steps:
  - run:
      name: Download << parameters.eval_platform >> eval binary
      environment:
        EVAL_PLATFORM: << parameters.eval_platform >>
      command: <<include(scripts/main.sh)>>
  - run:
      name: Run evaluation
      environment:
        CIRCLE_PIPELINE_ID: << parameters.circle_pipeline_id >>
        EVALS_RESULT_LOCATION: << parameters.evals_result_location >>
        EVAL_PLATFORM: << parameters.eval_platform >>
        BRAINTRUST_EXPERIMENT_NAME: << parameters.braintrust_experiment_name >>
        CCI_LANGCHAIN_EXPERIMENT_NAME: << parameters.langsmith_experiment_name >>
        LANGCHAIN_ENDPOINT: << parameters.langsmith_endpoint >>
        SHELL: << parameters.shell >>
      command: |
        if [ "$EVAL_PLATFORM" == "custom" ]; then
          cci-eval custom << parameters.cmd >>
        else
          cci-<< parameters.eval_platform >>-eval << parameters.cmd >>
        fi
  - store_artifacts:
      path: << parameters.evals_result_location >>
